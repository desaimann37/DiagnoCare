{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conv_base \u001b[38;5;241m=\u001b[39m \u001b[43mVGG16\u001b[49m(\n\u001b[0;32m      2\u001b[0m     weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     include_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m150\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VGG16' is not defined"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape=(150,150,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_pool False\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_pool True\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  print(layer.name,layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 7079424 (27.01 MB)\n",
      "Non-trainable params: 7635264 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Found 394 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# generators\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '../Dataset/BrainTumor/Training',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(150,150)\n",
    ")\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = '../Dataset/BrainTumor/Testing',\n",
    "    labels='inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size=32,\n",
    "    image_size=(150,150)\n",
    ")\n",
    "\n",
    "# Normalize\n",
    "def process(image,label):\n",
    "    image = tensorflow.cast(image/255. ,tensorflow.float32)\n",
    "    return image,label\n",
    "\n",
    "train_ds = train_ds.map(process)\n",
    "validation_ds = validation_ds.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 32\n",
    "\n",
    "# # Augmentation\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# # Define the preprocessing function\n",
    "# def process(image):\n",
    "#     image = tensorflow.cast(image/255., tensorflow.float32)\n",
    "#     return image\n",
    "\n",
    "# train_datagen.preprocessing_function = process\n",
    "# test_datagen.preprocessing_function = process\n",
    "\n",
    "# # Set the preprocessing function for train_generator\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         '../Dataset/BrainTumor/Training',\n",
    "#         target_size=(150, 150),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='sparse')\n",
    "\n",
    "# # Set the preprocessing function for validation_generator\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         '../Dataset/BrainTumor/Testing',\n",
    "#         target_size=(150, 150),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='sparse',\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pagha\\AppData\\Local\\Temp\\ipykernel_14200\\3141681306.py\", line 5, in <module>\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_167463]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# history = model.fit(\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#         train_generator,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#         epochs=10,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#         validation_data=validation_generator)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_ds,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39mvalidation_ds)\n",
      "File \u001b[1;32mc:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\pagha\\AppData\\Local\\Temp\\ipykernel_14200\\3141681306.py\", line 5, in <module>\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"c:\\Users\\pagha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_167463]"
     ]
    }
   ],
   "source": [
    "# history = model.fit(\n",
    "#         train_generator,\n",
    "#         epochs=10,\n",
    "#         validation_data=validation_generator)\n",
    "history = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load VGG16 model\n",
    "conv_base = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "# Set some layers to be trainable\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Build your model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators with data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../Dataset/BrainTumor/Training',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '../Dataset/BrainTumor/Testing',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Class weights\n",
    "class_weights = {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}  # Adjust weights based on your data distribution\n",
    "\n",
    "# Compile the model with class weights\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model with class weights\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
